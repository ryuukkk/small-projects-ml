{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T18:23:44.857034387Z",
     "start_time": "2024-02-01T18:23:44.548798566Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 17:15:07.873744: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-10 17:15:08.120291: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-10 17:15:08.793997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import threading\n",
    "import pickle\n",
    "import joblib\n",
    "import copy\n",
    "import threading\n",
    "from sklearn import preprocessing, model_selection, base, metrics, linear_model, pipeline, ensemble, svm, multiclass, neighbors, datasets, impute, compose\n",
    "from scipy import ndimage, spatial, stats\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4536f05a86ec32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T18:23:54.612233409Z",
     "start_time": "2024-02-01T18:23:54.461837341Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv('data/housing.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faccd40d102b728d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T18:23:59.269773839Z",
     "start_time": "2024-02-01T18:23:59.179700585Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "363a683e6e0c150d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T18:24:23.674543308Z",
     "start_time": "2024-02-01T18:24:23.469601058Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['ocean_proximity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8549a547cdadc739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:41:06.320733572Z",
     "start_time": "2024-01-31T20:41:06.275586015Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = housing.drop('median_house_value', axis=1), housing['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8790faa18b800667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:44:13.785266671Z",
     "start_time": "2024-01-31T20:44:13.707821717Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_sub = X['housing_median_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdc40f6135d938ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:44:14.545688653Z",
     "start_time": "2024-01-31T20:44:14.110337856Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0ce398b810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_sub[:50], y[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e5ff7408b842c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:47:46.636786698Z",
     "start_time": "2024-01-31T20:47:46.593823967Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit((X_sub.values).reshape(-1,1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5572e75e302666d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:48:07.988595375Z",
     "start_time": "2024-01-31T20:48:07.941452438Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011156305266710853"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_sub.values.reshape(-1,1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55f197a3fc2d4273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:49:28.360419032Z",
     "start_time": "2024-01-31T20:49:28.313747890Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_sub = X_sub.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42a80906630ac7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:49:39.619554610Z",
     "start_time": "2024-01-31T20:49:39.555595097Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly = preprocessing.PolynomialFeatures(degree=2)\n",
    "X_sub_new = poly.fit_transform(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb42b72b950b532b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:50:10.572880850Z",
     "start_time": "2024-01-31T20:50:10.501445268Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = linear_model.LinearRegression()\n",
    "lr2.fit(X_sub_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a203f47bc0c4186",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T20:50:19.829971388Z",
     "start_time": "2024-01-31T20:50:19.791840202Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'a', b'b', b'c'], dtype=object)>,\n",
       " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = tf.unique(tf.constant(['a', 'b', 'c', 'a']))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98c028a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(b, len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21043ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['a', 'b', 'c', 'd']\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "\n",
    "init_table = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "lookup_table = tf.lookup.StaticVocabularyTable(init_table, num_oov_buckets=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29e7389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 6), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(lookup_table.lookup(tf.constant(['a', 'b', 'b', 'a', 'e'])), depth=len(vocab)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28579145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.33301806, 0.3807509 ],\n",
       "       [0.5610728 , 0.71595013],\n",
       "       [0.5610728 , 0.71595013],\n",
       "       [0.33301806, 0.3807509 ],\n",
       "       [0.76269495, 0.02607489]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = tf.random.uniform((6, 2)) #discouraged\n",
    "\n",
    "cats = lookup_table.lookup(tf.constant(['a', 'b', 'b', 'a', 'e']))\n",
    "tf.nn.embedding_lookup(embedding, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8861ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.stateless_binomial(shape=[3], counts=[1, 2, 3], probs=0.5, seed=[0, 0])\n",
    "a = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7cd8b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (Ellipsis) with an unsupported type (<class 'ellipsis'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m rng \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mGenerator\u001b[38;5;241m.\u001b[39mfrom_seed(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1717\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Sample shape will be [3, 4, 3, 4, 2]\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m binomial_samples \u001b[38;5;241m=\u001b[39m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/ops/stateful_random_ops.py:867\u001b[0m, in \u001b[0;36mGenerator.binomial\u001b[0;34m(self, shape, counts, probs, dtype, name)\u001b[0m\n\u001b[1;32m    865\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m\"\u001b[39m, [shape, counts, probs]) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[0;32m--> 867\u001b[0m   counts \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcounts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m   probs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(probs, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    869\u001b[0m   shape_tensor \u001b[38;5;241m=\u001b[39m _shape_tensor(shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (Ellipsis) with an unsupported type (<class 'ellipsis'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    counts = [10., 20.]\n",
    "    # Probability of success.\n",
    "    probs = [0.8]\n",
    "\n",
    "    rng = tf.random.Generator.from_seed(seed=234)\n",
    "    binomial_samples = rng.binomial(shape=[2], counts=counts, probs=probs)\n",
    "\n",
    "\n",
    "    counts = ... # Shape [3, 1, 2]\n",
    "    probs = ...  # Shape [1, 4, 2]\n",
    "    shape = [3, 4, 3, 4, 2]\n",
    "    rng = tf.random.Generator.from_seed(seed=1717)\n",
    "    # Sample shape will be [3, 4, 3, 4, 2]\n",
    "    binomial_samples = rng.binomial(shape=shape, counts=counts, probs=probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4becfc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[0.33301806, 0.3807509 ],\n",
       "       [0.5610728 , 0.71595013],\n",
       "       [0.63383067, 0.26450765],\n",
       "       [0.59786415, 0.5320476 ],\n",
       "       [0.22355258, 0.9348483 ],\n",
       "       [0.76269495, 0.02607489]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b0d9080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tZXACedjmz kwUaqyeZDlleKCRZJvfrXSrmmKYKzqxCyvxxotHRZEfUXGOyqaBf UJnLBBYDnMuknmdFsTvPhlZwrZvJKvvAStCd'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "text = ''.join(random.choices(string.ascii_letters + ' ',  k=1000000))\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fae824d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18535,), dtype=int64, numpy=array([ 1039, 10248, 15806, ..., 12841,  6160,  9416])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = keras.layers.TextVectorization()\n",
    "tokenizer.adapt(tf.constant(text))\n",
    "text = tokenizer(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3579da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1039 10248 15806 ... 12841  6160  9416], shape=(18535,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 17:19:37.608620: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "text_tensor = tf.data.Dataset.from_tensor_slices([text])\n",
    "# text_tensor = text_tensor.window(100, 101, 1, True)\n",
    "for i in text_tensor.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ed82561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5fb3b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text_from_scratch(text, oov_buckets=10):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\r', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    \n",
    "    text = text.split(' ')\n",
    "    \n",
    "    vocab, _ = tf.unique(tf.constant(text))\n",
    "    indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "    \n",
    "    init_table = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "    lookup_table = tf.lookup.StaticVocabularyTable(init_table, num_oov_buckets=oov_buckets)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7af2eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerFromScratch(keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def adapt(self, text):\n",
    "        text = text.lower()\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = text.replace('\\r', ' ')\n",
    "        text = text.replace('\\t', ' ')\n",
    "\n",
    "        text = text.split(' ')\n",
    "\n",
    "        vocab, _ = tf.unique(tf.constant(text))\n",
    "        indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "\n",
    "        init_table = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "        self.lookup_table = tf.lookup.StaticVocabularyTable(init_table, num_oov_buckets=10)\n",
    "    \n",
    "    def call(self, text):\n",
    "        return self.lookup_table.lookup(text)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "350bf880",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TokenizerFromScratch()\n",
    "tokenizer.adapt(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ef7cb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([23647,   846])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tf.constant(['First', 'world']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d85efb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False,\n",
    "    vocabulary=None,\n",
    "    idf_weights=None,\n",
    "    sparse=False,\n",
    "    ragged=False,\n",
    "    encoding='utf-8',\n",
    "    name=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba6192f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.adapt(shakespeare_text)\n",
    "vectorizer.get_vocabulary()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b0df848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(202646,), dtype=int64, numpy=array([  89,  270,  138, ...,   26,  129, 1874])>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d54f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, vectorizer=vectorizer, train_size=0.9):\n",
    "    text = vectorizer(text)\n",
    "    train_size = int(len(text) * train_size)\n",
    "    text_dataset_train, text_dataset_test = tf.data.Dataset.from_tensor_slices(text[:train_size]), tf.data.Dataset.from_tensor_slices(text[train_size:])\n",
    "    return text_dataset_train, text_dataset_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03aad9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>,\n",
       " <_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset_train, text_dataset_test = preprocess(shakespeare_text)\n",
    "text_dataset_train, text_dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ef738ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(89, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 18:31:13.255228: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for i in text_dataset_train.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b21b06f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[UNK] the and to i'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_vocabulary()\n",
    "index_lookup = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "def tokens_to_text(sequence):\n",
    "    return \" \".join([index_lookup[token] for token in sequence if token != 0])\n",
    "\n",
    "tokens_to_text([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2aa9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = text_dataset_train.window(size=101, shift=1, stride=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5cbd5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  89  270  138 ...   60   58  573]\n",
      " [ 270  138   36 ...   58  573   79]\n",
      " [ 138   36  982 ...  573   79   22]\n",
      " ...\n",
      " [ 270   89    7 ...   79    2 2346]\n",
      " [  89    7   93 ...    2 2346    6]\n",
      " [   7   93 1187 ... 2346    6   40]], shape=(32, 101), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 18:39:27.737226: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "window_flat = window.flat_map(lambda x: x.batch(101))\n",
    "for i in window_flat.batch(32).take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f48bf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = window_flat.shuffle(10000).batch(32)\n",
    "dataset = dataset.map(lambda x: (x[:, :-1], x[:, 1:]))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fc27b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "emb = keras.layers.Embedding(input_dim=vocab_size, output_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9e3a614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 100), dtype=int64, numpy=\n",
      "array([[    5,    15,   215, ...,  8970,  4445,    28],\n",
      "       [  497,    14,    79, ...,  1636,     8,   502],\n",
      "       [12414,   483,    27, ...,    99,     4,   101],\n",
      "       ...,\n",
      "       [  106,   293,   120, ...,   167,  1450,    13],\n",
      "       [   19,  4222,    57, ...,    90,    55,     7],\n",
      "       [    3,    46,  2095, ...,    73,  1055,  1560]])>, <tf.Tensor: shape=(32, 100), dtype=int64, numpy=\n",
      "array([[  15,  215,   10, ..., 4445,   28,  269],\n",
      "       [  14,   79,  139, ...,    8,  502,    5],\n",
      "       [ 483,   27,  141, ...,    4,  101,    3],\n",
      "       ...,\n",
      "       [ 293,  120, 1730, ..., 1450,   13,   22],\n",
      "       [4222,   57,    2, ...,   55,    7,   87],\n",
      "       [  46, 2095,    6, ..., 1055, 1560,  752]])>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 19:13:54.212754: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print((i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5a7e3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    emb,\n",
    "    keras.layers.LSTM(32, return_sequences=True),\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bffde163",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3dad12de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 19:13:07.542320: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: -input rank(-1) <= split_dim < input rank (1), but got 1\n",
      "2024-07-10 19:13:07.543452: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: In[0] and In[1] has different ndims: [32,32] vs. [0]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling LSTMCell.call().\n\n\u001b[1m{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] and In[1] has different ndims: [32,32] vs. [0] [Op:MatMul] name: \u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(32, 32), dtype=float32)\n  • states=('tf.Tensor(shape=(32, 32), dtype=float32)', 'tf.Tensor(shape=(32, 32), dtype=float32)')\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling LSTMCell.call().\n\n\u001b[1m{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] and In[1] has different ndims: [32,32] vs. [0] [Op:MatMul] name: \u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(32, 32), dtype=float32)\n  • states=('tf.Tensor(shape=(32, 32), dtype=float32)', 'tf.Tensor(shape=(32, 32), dtype=float32)')\n  • training=False"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(model(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "df8793e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thory/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_38 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_39 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "     91/Unknown \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.0369 - loss: 8.7538"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Assuming dataset is already defined\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Adjust labels to match the expected shape\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# def preprocess_data(X, y):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed\n",
    "\n",
    "# Example parameters\n",
    "vocab_size = 20000  # Adjust based on your vocabulary size\n",
    "embedding_dim = 32\n",
    "sequence_length = 100  # The length of the sequences in the dataset\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dense(vocab_size, activation='softmax')  # Output layer for each time step\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Assuming dataset is already defined\n",
    "# Adjust labels to match the expected shape\n",
    "# def preprocess_data(X, y):\n",
    "#     return X, tf.expand_dims(y, -1)\n",
    "\n",
    "# dataset = dataset.map(preprocess_data)\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b347640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
