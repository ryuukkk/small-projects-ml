{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation\n",
    "import threading\n",
    "import pickle\n",
    "import joblib\n",
    "import copy\n",
    "import threading\n",
    "from sklearn import impute, preprocessing, model_selection, base, metrics, linear_model, pipeline, ensemble, svm, multiclass, neighbors, compose, datasets, decomposition, manifold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from scratch_models import my_decorators\n",
    "import gym\n",
    "import pygame as pg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd0fb9d0358ad7e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Environment\n",
    "**Setup the CartPole environment**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37564b75be5662c0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "clock = pg.time.Clock()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10696c005d35255e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Define a Policy**\n",
    "It can either be User Controlled (``rl=None``), or a simple harcoded policy (``rl='basic'``) or a Neural Network based policy (``rl='nn'``)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "206386f05e3775ae"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def policy(obs, rl=None):\n",
    "    action = None\n",
    "    if rl is None:\n",
    "        return action\n",
    "\n",
    "    if rl=='basic':\n",
    "        angle = obs[2]\n",
    "        action = 1 if angle>0 else 0\n",
    "        return action\n",
    "\n",
    "    if rl=='nn':\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a3797c73fcf1957"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Simulations**\n",
    "Next, I shall create some functions to simulate the CartPole environment based on different policies."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96ca586d17805c95"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Run animations\n",
    "def animate(env, win, clock):\n",
    "    clock.tick(15)\n",
    "    run = True\n",
    "    frame = env.render()\n",
    "    frame = np.rot90(frame)\n",
    "    frame = np.flipud(frame)\n",
    "    surface = pg.surfarray.make_surface(frame)\n",
    "\n",
    "    win.blit(surface, (0, 0))\n",
    "    pg.display.update()\n",
    "\n",
    "    for event in pg.event.get():\n",
    "        if event.type == pg.QUIT:\n",
    "            run = False\n",
    "            pg.quit()\n",
    "    return run\n",
    "            \n",
    "# User controlled settings if no policy     \n",
    "def run_by_user(animation):\n",
    "    action = None\n",
    "    if animation:\n",
    "        user_input = pg.key.get_pressed()\n",
    "        if user_input[pg.K_RIGHT]:\n",
    "            action = 1\n",
    "        elif user_input[pg.K_LEFT]:\n",
    "            action = 0\n",
    "        return action\n",
    "    else:\n",
    "        raise ValueError('Animation must be True in user-controlled policy')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b999f6a3a8d16037"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# List that holds rewards for each run\n",
    "env_rewards = []\n",
    "\n",
    "# Main function to run the simulation\n",
    "def simulate_episode(env, policy_type=None, animation=True):\n",
    "    obs, info = env.reset()\n",
    "    clock = pg.time.Clock()\n",
    "    \n",
    "    # Initialize Pygame if animation is True\n",
    "    if animation:\n",
    "        clock.tick(15)\n",
    "        win = pg.display.set_mode((600, 400))\n",
    "        pg.init()\n",
    "        run = True\n",
    "    else:\n",
    "        run = 500\n",
    "\n",
    "\n",
    "    episode_rewards = 0\n",
    "    while run:        \n",
    "        action=policy(obs, policy_type)\n",
    "        \n",
    "        # For User controlled setting\n",
    "        if action is None:\n",
    "            action = run_by_user(animation)\n",
    "                \n",
    "        if action is not None:\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "            episode_rewards += reward\n",
    "            if done:                                                # COMMENT THIS SECTION OUT FOR DEMONSTRATION\n",
    "                obs, info = env.reset()\n",
    "                break\n",
    "        \n",
    "        if animation:\n",
    "            run = animate(env, win, clock)\n",
    "        else:\n",
    "            run-=1\n",
    "    \n",
    "    env_rewards.append((policy_type,episode_rewards))\n",
    "    env.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f647d5e5a6dacd2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. User Controlled**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fd90a38b76c1b99"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "simulate_episode(env, animation=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55a0f25278a2e821"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Hard-coded Policy**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f40d5999b56960b"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "simulate_episode(env, policy_type='basic', animation=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0f1585b2a1df5d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us check the performance of this basic policy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72fb00ad2b64c72e"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "simulate_episode(env, policy_type='basic', animation=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a0b97fc4488d763"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Let it learn for 500 runs\n",
    "for episode in range(500):\n",
    "    simulate_episode(env, policy_type='basic' ,animation=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d763e3a0a47dc3c2"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "('basic', 68.0)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(env_rewards)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "618fba51f3e60b02"
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the hard-coded policy it could run a max of 68 steps before falling down."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e60cecd7a2313152"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c571376051fbd7b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
