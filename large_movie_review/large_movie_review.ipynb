{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import requests\n",
    "import os\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Get Data**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ac5ef6d057c52fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "URL = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "DATA_DIR = 'data'\n",
    "ROOT_DIR = ''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:08:35.327949215Z",
     "start_time": "2024-02-12T01:08:35.321896763Z"
    }
   },
   "id": "a1ad5e177f7a0ffd",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_data(url=URL, root_dir=ROOT_DIR, data_dir=DATA_DIR):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    with open('temp.tar.gz', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    with tarfile.open('temp.tar.gz', 'r:gz') as tar_file:\n",
    "        tar_file.extractall(path=root_dir)\n",
    "    \n",
    "    os.remove('temp.tar.gz')\n",
    "    os.rename('aclImdb', data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T20:25:00.255093249Z",
     "start_time": "2024-02-06T20:25:00.212499328Z"
    }
   },
   "id": "8eb938022784eda5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "get_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T20:25:19.055573112Z",
     "start_time": "2024-02-06T20:25:01.598695600Z"
    }
   },
   "id": "39e34e1239bdb989",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "PosixPath('data')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = DATA_DIR\n",
    "path = Path(filepath)\n",
    "path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:08:35.335652852Z",
     "start_time": "2024-02-12T01:08:35.327910780Z"
    }
   },
   "id": "4e00b7d4feb85680",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def review_paths(dirpath):\n",
    "    return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_neg = review_paths(path / \"test\" / \"neg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:08:35.478351989Z",
     "start_time": "2024-02-12T01:08:35.339076603Z"
    }
   },
   "id": "ab937924faca9f9f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "12500"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pos)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:08:35.530993170Z",
     "start_time": "2024-02-12T01:08:35.481961258Z"
    }
   },
   "id": "2345ae8f03a78aa3",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train-Test-Valid Split**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33b9017df0cd415b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.random.shuffle(test_pos)\n",
    "np.random.shuffle(test_neg)\n",
    "\n",
    "valid_pos = test_pos[5000:]\n",
    "valid_neg = test_neg[5000:]\n",
    "test_pos = test_pos[:5000]\n",
    "test_neg = test_neg[:5000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:08:35.532082228Z",
     "start_time": "2024-02-12T01:08:35.529504592Z"
    }
   },
   "id": "6aa8d9cc1fe3b882",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(5000, 7500)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pos), len(valid_pos)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:08:49.410463631Z",
     "start_time": "2024-02-12T01:08:49.405569012Z"
    }
   },
   "id": "31061e7a8d30b48c",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Preprocessing**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e96fb0ca8fa53e1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Python way\n",
    "def imdb_dataset(filepaths_pos, filepaths_neg):\n",
    "    reviews=[]\n",
    "    labels=[]\n",
    "    for filepaths, label in ((filepaths_pos, 1), (filepaths_neg, 0)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath, 'r') as fp:\n",
    "                reviews.append(fp.read())\n",
    "            labels.append(label)\n",
    "    X = tf.constant(reviews)\n",
    "    y = tf.constant(labels)\n",
    "    return tf.data.Dataset.from_tensor_slices((X,y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:32:56.882104458Z",
     "start_time": "2024-02-12T01:32:56.877182097Z"
    }
   },
   "id": "1b63db469553a211",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = imdb_dataset(train_pos, train_neg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:32:58.454452523Z",
     "start_time": "2024-02-12T01:32:57.853067065Z"
    }
   },
   "id": "4bcc4ba35c6d0e76",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"Despite Disney's best efforts, this is a rather enjoyable movie about following your dreams. I was surprised that it didn't strike me as over-sentimental; this movie played fair. Dennis Quaid was very, very good in the role, which is saying something for a sports movie. I can't recall how many sports movies have had little quirks that bother me; here, everybody looks the part. This movie is surprisingly good, and I predict that it will do surprising business as it is a G-rated movie that doesn't require the viewer to stop thinking. Ebert to the contrary, this movie is a success.\">, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:48:38.539009688Z",
     "start_time": "2024-02-12T01:48:38.492095544Z"
    }
   },
   "id": "b6572d11f70659fc",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tensorflow way\n",
    "def imdb_dataset_2(filepaths_pos, filepaths_neg, num_parallel_calls=tf.data.experimental.AUTOTUNE):\n",
    "    dataset_pos = tf.data.TextLineDataset(filepaths_pos, num_parallel_reads=num_parallel_calls)\n",
    "    dataset_pos = dataset_pos.map(lambda review: (review, 1))\n",
    "    dataset_neg = tf.data.TextLineDataset(filepaths_neg, num_parallel_reads=num_parallel_calls)\n",
    "    dataset_neg = dataset_neg.map(lambda review: (review, 0))\n",
    "    dataset = tf.data.Dataset.concatenate(dataset_pos, dataset_neg)\n",
    "    return dataset    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:48:34.011633781Z",
     "start_time": "2024-02-12T01:48:33.989437409Z"
    }
   },
   "id": "6cb127b5a9896939",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = imdb_dataset_2(train_pos, train_neg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T01:48:34.980634448Z",
     "start_time": "2024-02-12T01:48:34.828531201Z"
    }
   },
   "id": "4c09a59e04793cad",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Saving the Dataset**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b721a194a58ac665"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(type(tf.io.serialize_tensor(i[0]).numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T04:06:01.206534487Z",
     "start_time": "2024-02-12T04:06:01.079632598Z"
    }
   },
   "id": "7278d3eeb231ece0",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):  # If value is Tensor\n",
    "        value = tf.compat.as_bytes(value.numpy().decode('utf-8'))  # Requires eager execution!\n",
    "    else:\n",
    "        value = tf.compat.as_bytes(value)  # Directly convert string to bytes\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T04:18:21.625263387Z",
     "start_time": "2024-02-12T04:18:21.584082866Z"
    }
   },
   "id": "93c7d04518fb8e61",
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@tf.py_function(Tout=tf.string)\n",
    "def serialize_example(review, label):\n",
    "    features = {\n",
    "        'review': _bytes_feature(review),\n",
    "        'label': _int64_feature(label)\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return example_proto.SerializeToString()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T04:20:25.286280861Z",
     "start_time": "2024-02-12T04:20:25.252019511Z"
    }
   },
   "id": "bbc1158dc15315ff",
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Putting it all together**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5945f73f4b9e2380"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def store_in_tfrecord(pos_path, neg_path, target_path):\n",
    "    dataset = imdb_dataset_2(pos_path, neg_path)\n",
    "    serialized_dataset = dataset.map(lambda review, label: tf.py_function(\n",
    "        serialize_example, [review, label], tf.string),\n",
    "                                     num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    writer = tf.data.experimental.TFRecordWriter(target_path)\n",
    "    writer.write(serialized_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T04:21:50.295207706Z",
     "start_time": "2024-02-12T04:21:50.271104558Z"
    }
   },
   "id": "cc8a1a0d8c70de28",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_4149/2175349272.py:7: TFRecordWriter.__init__ (from tensorflow.python.data.experimental.ops.writers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To write TFRecords to disk, use `tf.io.TFRecordWriter`. To save and load the contents of a dataset, use `tf.data.experimental.save` and `tf.data.experimental.load`\n"
     ]
    }
   ],
   "source": [
    "store_in_tfrecord(train_pos, train_neg, 'data/train.tfrecord')\n",
    "store_in_tfrecord(valid_pos, valid_neg, 'data/valid.tfrecord')\n",
    "store_in_tfrecord(test_pos, valid_neg, 'data/test.tfrecord')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T04:22:24.918925145Z",
     "start_time": "2024-02-12T04:21:50.832777501Z"
    }
   },
   "id": "f2ac4906d8a1c9b",
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Loading**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "818b4fde5eba121d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38c459f3caa66711"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
